getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
getting started
starting main
getting started
starting main
getting started
starting main
getting started
starting main
getting started
starting main
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
we are in apply memit to model
copied weights
inside execute_memit
deepcopied requests
MEMIT request sample: [Lee Alvin DuBridge's area of work is] -> [ diplomat]
MEMIT request sample: [John Henry Poynting's domain of activity is] -> [ mathematics]
MEMIT request sample: [Yi-Fu Tuan's expertise is] -> [ singing]
MEMIT request sample: [Michel Chasles's domain of work is] -> [ physics]
MEMIT request sample: [Onufri works in the field of] -> [ astronomy]
MEMIT request sample: [Jonathan Haidt works in the field of] -> [ geometry]
MEMIT request sample: [A Thousand Plateaus's domain of activity is] -> [ physics]
MEMIT request sample: [The expertise of The Astronomical Journal is] -> [ algebra]
MEMIT request sample: [suicide attack specializes in] -> [ physiology]
MEMIT request sample: [The domain of activity of Georg Ernst Stahl is] -> [ mathematics]
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
we are in apply memit to model
copied weights
inside execute_memit
deepcopied requests
MEMIT request sample: [Lee Alvin DuBridge's area of work is] -> [ diplomat]
MEMIT request sample: [John Henry Poynting's domain of activity is] -> [ mathematics]
MEMIT request sample: [Yi-Fu Tuan's expertise is] -> [ singing]
MEMIT request sample: [Michel Chasles's domain of work is] -> [ physics]
MEMIT request sample: [Onufri works in the field of] -> [ astronomy]
MEMIT request sample: [Jonathan Haidt works in the field of] -> [ geometry]
MEMIT request sample: [A Thousand Plateaus's domain of activity is] -> [ physics]
MEMIT request sample: [The expertise of The Astronomical Journal is] -> [ algebra]
MEMIT request sample: [suicide attack specializes in] -> [ physiology]
MEMIT request sample: [The domain of activity of Georg Ernst Stahl is] -> [ mathematics]
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
we are in apply memit to model
copied weights
inside execute_memit
deepcopied requests
MEMIT request sample: [Lee Alvin DuBridge's area of work is] -> [ diplomat]
MEMIT request sample: [John Henry Poynting's domain of activity is] -> [ mathematics]
MEMIT request sample: [Yi-Fu Tuan's expertise is] -> [ singing]
MEMIT request sample: [Michel Chasles's domain of work is] -> [ physics]
MEMIT request sample: [Onufri works in the field of] -> [ astronomy]
MEMIT request sample: [Jonathan Haidt works in the field of] -> [ geometry]
MEMIT request sample: [A Thousand Plateaus's domain of activity is] -> [ physics]
MEMIT request sample: [The expertise of The Astronomical Journal is] -> [ algebra]
MEMIT request sample: [suicide attack specializes in] -> [ physiology]
MEMIT request sample: [The domain of activity of Georg Ernst Stahl is] -> [ mathematics]
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
we are in apply memit to model
copied weights
inside execute_memit
deepcopied requests
MEMIT request sample: [Lee Alvin DuBridge's area of work is] -> [ diplomat]
MEMIT request sample: [John Henry Poynting's domain of activity is] -> [ mathematics]
MEMIT request sample: [Yi-Fu Tuan's expertise is] -> [ singing]
MEMIT request sample: [Michel Chasles's domain of work is] -> [ physics]
MEMIT request sample: [Onufri works in the field of] -> [ astronomy]
MEMIT request sample: [Jonathan Haidt works in the field of] -> [ geometry]
MEMIT request sample: [A Thousand Plateaus's domain of activity is] -> [ physics]
MEMIT request sample: [The expertise of The Astronomical Journal is] -> [ algebra]
MEMIT request sample: [suicide attack specializes in] -> [ physiology]
MEMIT request sample: [The domain of activity of Georg Ernst Stahl is] -> [ mathematics]
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_002/{}_edits-case_{}.json
about to start 73
started 73
we are in apply memit to model
copied weights
inside execute_memit
deepcopied requests
MEMIT request sample: [Lee Alvin DuBridge's area of work is] -> [ diplomat]
MEMIT request sample: [John Henry Poynting's domain of activity is] -> [ mathematics]
MEMIT request sample: [Yi-Fu Tuan's expertise is] -> [ singing]
MEMIT request sample: [Michel Chasles's domain of work is] -> [ physics]
MEMIT request sample: [Onufri works in the field of] -> [ astronomy]
MEMIT request sample: [Jonathan Haidt works in the field of] -> [ geometry]
MEMIT request sample: [A Thousand Plateaus's domain of activity is] -> [ physics]
MEMIT request sample: [The expertise of The Astronomical Journal is] -> [ algebra]
MEMIT request sample: [suicide attack specializes in] -> [ physiology]
MEMIT request sample: [The domain of activity of Georg Ernst Stahl is] -> [ mathematics]
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_002/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_003/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_004/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_005/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_006/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_002/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_003/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_004/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_005/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_006/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_007/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_008/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_002/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
Execution took 16320.286709547043
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 73
started 73
Execution took 248.67592573165894
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 21528
started 21528
Execution took 243.92279052734375
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 0
started 0
Execution took 3382.356870174408
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
getting started
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P19_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 147.7723090648651
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 1143.0368647575378
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
Execution took 161.30431604385376
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
Execution took 1144.0990717411041
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
Execution took 1167.0047566890717
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
Execution took 143.05087804794312
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 1055.1465473175049
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22939
started 22939
Execution took 133.06833004951477
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
Execution took 266.8135643005371
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
Execution took 258.7222948074341
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 252.08903408050537
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 258.5977749824524
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 238.82133722305298
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
Execution took 107580.6283853054
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
Execution took 3662.168657064438
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 3431.2811212539673
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 3630.8355050086975
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
Execution took 3614.8000514507294
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
Execution took 3746.849238395691
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
Execution took 3709.6241381168365
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistral/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 3695.9400334358215
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 284.6554090976715
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 277.7940547466278
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 267.9586682319641
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P103_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P103_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
Execution took 399.88511657714844
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_NONE/P103_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-Instruct-v0.2_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/mistral/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
Execution took 1669.1501038074493
about to evaluate
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Instantiating model
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
Execution took 73685.60625934601
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
Execution took 280.08939933776855
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 3570.9451875686646
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 3678.6002621650696
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
Execution took 3683.3377861976624
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
Execution took 3756.026092529297
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
Execution took 3705.3096253871918
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/mistralb/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 3690.993649959564
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 285.1843328475952
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 277.6836221218109
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 268.7852644920349
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
Execution took 391.5255272388458
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/mistralai_Mistral-7B-v0.1_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/mistralb/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
Execution took 9210.278901815414
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 22210
started 22210
Execution took 100272.92544555664
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 23904
started 23904
Execution took 2891.6062364578247
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 2576.6933913230896
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 2918.4741032123566
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 23622
started 23622
Execution took 2898.064904689789
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 23343
started 23343
Execution took 2853.7498848438263
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 22489
started 22489
Execution took 2545.9775927066803
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 2433.730547428131
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 252.69103574752808
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 258.9594714641571
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 22775
started 22775
Execution took 238.63101768493652
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 73
started 73
Execution took 3344.5645570755005
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 0
started 0
Execution took 8086.244698524475
about to evaluate
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P101_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P19_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P101_P27_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P21_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P101_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P19_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P101_P27_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P19_P21_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on pair/llamac/MEMIT/run_000/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 276.0104582309723
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P19_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P101_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 296.102840423584
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
Execution took 289.7584800720215
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P19_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P103_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P103_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 0
started 0
Execution took 8632.937182188034
about to evaluate
getting started
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_000/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P21_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P21_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 21920
started 21920
Execution took 4295.623036623001
about to evaluate
getting started
starting main
Instantiating model
created model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_NONE/P27_P101_layer_{}_clamp_{}_case_{}.npz
about to evaluate
getting started
starting main
Executing MEMIT with parameters MEMITHyperParams(layers=[4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=31, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', stats_dir='./data/stats', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')
Instantiating model
Loading dataset, attribute snippets, tf-idf data
Will load cache from kvs/meta-llama_Llama-2-7b-chat-hf_MEMIT/P27_P101_layer_{}_clamp_{}_case_{}.npz
working on results/llamac/MEMIT/run_001/{}_edits-case_{}.json
about to start 23061
started 23061
